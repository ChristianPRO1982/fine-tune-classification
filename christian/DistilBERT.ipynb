{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUGGINGFACE + TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### PREPARATION\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>cat</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>class</th>\n",
       "      <th>class_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.tourisme-cambresis.fr/1-les-templi...</td>\n",
       "      <td>Aventure-jeu : \"Les Templiers du coffre d'or\"</td>\n",
       "      <td>Le jeu aventure « Les templiers du coffre d’or...</td>\n",
       "      <td>17</td>\n",
       "      <td>Jeu</td>\n",
       "      <td>Famille</td>\n",
       "      <td>Détente</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.tourisme-cambresis.fr/1-les-templi...   \n",
       "\n",
       "                                           title  \\\n",
       "0  Aventure-jeu : \"Les Templiers du coffre d'or\"   \n",
       "\n",
       "                                         description  cat cat1     cat2  \\\n",
       "0  Le jeu aventure « Les templiers du coffre d’or...   17  Jeu  Famille   \n",
       "\n",
       "      cat3   class  class_number  \n",
       "0  Détente  Action           0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset.csv')\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb ligne df 391\n",
      "nb ligne df1 390\n",
      "nb ligne df2 317\n",
      "nb ligne df3 134\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.tourisme-cambresis.fr</td>\n",
       "      <td>https://www.tourisme-cambresis.fr/1-les-templi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain  \\\n",
       "0  www.tourisme-cambresis.fr   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.tourisme-cambresis.fr/1-les-templi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_domain(url):\n",
    "    url = url[url.find('//')+2:]\n",
    "    url = url[:url.find('/')]\n",
    "    return url\n",
    "\n",
    "df['domain'] = df['url'].apply(extract_domain)\n",
    "\n",
    "print(\"nb ligne df\", len(df))\n",
    "\n",
    "df = df.dropna(subset=['description'])\n",
    "\n",
    "print(\"nb ligne df1\", len(df))\n",
    "\n",
    "df1 = df.copy()\n",
    "df2 = df.dropna(subset=['cat2'])\n",
    "df3 = df.dropna(subset=['cat3'])\n",
    "\n",
    "print(\"nb ligne df2\", len(df2))\n",
    "print(\"nb ligne df3\", len(df3))\n",
    "\n",
    "df[['domain', 'url']].head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.tourisme-cambresis.fr | Aventure-jeu : \"Le...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  www.tourisme-cambresis.fr | Aventure-jeu : \"Le...     17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concaténer les colonnes 'title' et 'description' pour former les textes\n",
    "df1['text'] = df1['domain'] + \" | \" + df1['title'] + \" \" + df1['description']\n",
    "# df1['text'] = df1['title']\n",
    "df1['label'] = df1['cat']\n",
    "\n",
    "df_ml = df1[['text', 'label']]\n",
    "df_ml.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Documents/projects/DEV_IA/fine-tune-classification/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "df_train = df_ml.iloc[:190]\n",
    "df_test = df_ml.iloc[190:380]\n",
    "df_unsupervised = df_ml.iloc[380:]\n",
    "\n",
    "# Conversion des DataFrames en Datasets\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "dataset_unsupervised = Dataset.from_pandas(df_unsupervised)\n",
    "\n",
    "# Créer un DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'test': dataset_test,\n",
    "    'unsupervised': dataset_unsupervised\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 190\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# imdb = load_dataset('imdb')\n",
    "imdb = dataset_dict\n",
    "imdb = imdb.remove_columns([\"__index_level_0__\"])\n",
    "imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'www.tourismevalenciennes.fr | Exposition \"Quand la nature inspire l\\'innovation\" - Famars Va prendre tes leçons dans la nature, c’est là qu’est notre futur.\\nLéonard de Vinci\\n\\n\\nCe temps fort exceptionnel, préfiguration à la grande exposition Biomimétisme prévue en septembre 2024, réunira durant 3 semaines une exposition, des ateliers, une conférence…\\n\\nLe biomimétisme, littéralement, l’imitation du vivant, consiste à s’inspirer de la nature pour concevoir de nouvelles technologies, innover. C’est, par exemple, en s’inspirant des oiseaux et de leurs ailes que sont nés les premiers ancêtres des avions. Que de chemin parcouru depuis, dans tous les domaines !\\n\\nL’EXPOSITION*, du 2 au 20 octobre, accessible dès 10 ans, sera certainement une révélation pour beaucoup de visiteurs !\\nÀ travers quelques exemples concrets, on découvre comment le vivant a été, est et sera une source d’inspiration exceptionnelle pour l’innovation. L’Aviation, le ferroviaire, le sport, l’automobile sont autant de secteurs industriels majeurs pour qui l’observation de la nature demeure un travail fondamental. À partir de ces observations, des avancées majeures ont pu avoir lieu.\\n\\nAujourd’hui, le biomimétisme peut apporter des solutions aux grands enjeux de développement durable auxquels nous sommes tous confrontés.\\nLa biodiversité n’est pas uniquement un espace fragile à protéger, c’est aussi une bibliothèque de technologies et une incroyable source d’inspirations !\\n\\n*Retrouvez les différents tarifs sur le site Internet*',\n",
       " 'label': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"test\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# générateur de tokens\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de prétraitement des tokens pour les tronqués pour par qu'ils dépassent la longueur max d'entrée du modèle\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 190/190 [00:00<00:00, 3167.37 examples/s]\n",
      "Map: 100%|██████████| 190/190 [00:00<00:00, 3856.85 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 1516.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# application de la fonction avec un accélérateur de mapping\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you like, you can create a smaller subset of the full dataset to fine-tune on to reduce the time it takes\n",
    "small_train_dataset = tokenized_imdb[\"train\"].shuffle(seed=42).select(range(190))\n",
    "small_eval_dataset = tokenized_imdb[\"test\"].shuffle(seed=42).select(range(190))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 11:02:51.884380: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 11:02:53.072789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Now create a batch of examples using DataCollatorWithPadding. It’s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# TS\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### HYPERPARAMETRES\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'Action', 1: 'Art', 2: 'Atelier', 3: 'Balade', 4: 'Brocante', 5: 'Concert', 6: 'Conférence', 7: 'Culture', 8: 'Danse', 9: 'Détente', 10: 'Environnement', 11: 'Exposition', 12: 'Famille', 13: 'Festival', 14: 'Fête', 15: 'Gastronomie', 16: 'Histoire', 17: 'Jeu', 18: 'Marché', 19: 'Santé', 20: 'Spectacle', 21: 'Sport', 22: 'Théatre', 23: 'Visite'}\n",
      "label2id: {'Action': 0, 'Art': 1, 'Atelier': 2, 'Balade': 3, 'Brocante': 4, 'Concert': 5, 'Conférence': 6, 'Culture': 7, 'Danse': 8, 'Détente': 9, 'Environnement': 10, 'Exposition': 11, 'Famille': 12, 'Festival': 13, 'Fête': 14, 'Gastronomie': 15, 'Histoire': 16, 'Jeu': 17, 'Marché': 18, 'Santé': 19, 'Spectacle': 20, 'Sport': 21, 'Théatre': 22, 'Visite': 23}\n"
     ]
    }
   ],
   "source": [
    "# création de IDs pour les labels\n",
    "# id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "# label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "\n",
    "id2label[0] = 'Action'\n",
    "id2label[1] = 'Art'\n",
    "id2label[2] = 'Atelier'\n",
    "id2label[3] = 'Balade'\n",
    "id2label[4] = 'Brocante'\n",
    "id2label[5] = 'Concert'\n",
    "id2label[6] = 'Conférence'\n",
    "id2label[7] = 'Culture'\n",
    "id2label[8] = 'Danse'\n",
    "id2label[9] = 'Détente'\n",
    "id2label[10] = 'Environnement'\n",
    "id2label[11] = 'Exposition'\n",
    "id2label[12] = 'Famille'\n",
    "id2label[13] = 'Festival'\n",
    "id2label[14] = 'Fête'\n",
    "id2label[15] = 'Gastronomie'\n",
    "id2label[16] = 'Histoire'\n",
    "id2label[17] = 'Jeu'\n",
    "id2label[18] = 'Marché'\n",
    "id2label[19] = 'Santé'\n",
    "id2label[20] = 'Spectacle'\n",
    "id2label[21] = 'Sport'\n",
    "id2label[22] = 'Théatre'\n",
    "id2label[23] = 'Visite'\n",
    "\n",
    "\n",
    "label2id['Action'] = 0\n",
    "label2id['Art'] = 1\n",
    "label2id['Atelier'] = 2\n",
    "label2id['Balade'] = 3\n",
    "label2id['Brocante'] = 4\n",
    "label2id['Concert'] = 5\n",
    "label2id['Conférence'] = 6\n",
    "label2id['Culture'] = 7\n",
    "label2id['Danse'] = 8\n",
    "label2id['Détente'] = 9\n",
    "label2id['Environnement'] = 10\n",
    "label2id['Exposition'] = 11\n",
    "label2id['Famille'] = 12\n",
    "label2id['Festival'] = 13\n",
    "label2id['Fête'] = 14\n",
    "label2id['Gastronomie'] = 15\n",
    "label2id['Histoire'] = 16\n",
    "label2id['Jeu'] = 17\n",
    "label2id['Marché'] = 18\n",
    "label2id['Santé'] = 19\n",
    "label2id['Spectacle'] = 20\n",
    "label2id['Sport'] = 21\n",
    "label2id['Théatre'] = 22\n",
    "label2id['Visite'] = 23\n",
    "\n",
    "print(\"id2label:\", id2label)\n",
    "print(\"label2id:\", label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entraienement avec DistilBERT\n",
    "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"my_awesome_model\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     num_train_epochs=2,\n",
    "#     weight_decay=0.01,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     push_to_hub=False,\n",
    "#     no_cuda=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### EVALUATION\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  avec fonction évaluer les prédictions\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrics\n",
    "# import numpy as np\n",
    "# import evaluate\n",
    "\n",
    "# metric = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitoring\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### ENTRAINEMENT\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=small_train_dataset,\n",
    "#     eval_dataset=small_eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     data_collator=data_collator,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que le GPU est désactivé dans torch également\n",
    "# import torch\n",
    "# torch.cuda.is_available = lambda: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "# Tensorflow\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 11:02:56.189080: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 11:02:56.189782: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# TS\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(tokenized_imdb[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_imdb[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_imdb[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)  # No loss argument!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/utilisateur/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "<> login huggingface <>\n",
      "PlumePJ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login('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')\n",
    "print()\n",
    "print('<> login huggingface <>')\n",
    "os.system('huggingface-cli whoami')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Documents/projects/DEV_IA/fine-tune-classification/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/utilisateur/Documents/projects/DEV_IA/fine-tune-classification/christian/my_awesome_model is already a clone of https://huggingface.co/PlumePJ/my_awesome_model. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x734ee7328720> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x734ee7328720> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
