{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximekuil/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from labels import LABELS\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"ethos\", \"multilabel\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "data = \"./dataset_resume.csv\"\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "df_new = df.copy()\n",
    "# on stocke la classification\n",
    "features = df_new[LABELS]\n",
    "# création d'une colonne labels pour représenter tous les labels de la description\n",
    "df_new[\"labels\"] = pd.Series().fillna(\"\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def setup(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # s'il y a un résumé, on l'utilise comme description\n",
    "        df.loc[index, \"description\"] = (\n",
    "                row.resume\n",
    "                if isinstance(row.resume, str)\n",
    "                else row.description\n",
    "            )\n",
    "    \n",
    "        features = row[LABELS]\n",
    "        df.at[index, \"labels\"] = [feature for feature in features]\n",
    "    \n",
    "    df.drop(columns=['resume', 'title'], inplace=True)\n",
    "    df.drop(columns=LABELS, inplace=True)\n",
    "    # suppression de l'index\n",
    "    df = df.iloc[:, 1:]\n",
    "\n",
    "    train_df, test_data = train_test_split(\n",
    "        df, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_df, test_df = train_test_split(test_data, test_size=0.5)\n",
    "\n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "train_df, test_df, val_df = setup(df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryTable\n",
       "description: string\n",
       "labels: list<item: double>\n",
       "  child 0, item: double\n",
       "__index_level_0__: int64\n",
       "----\n",
       "description: [[\"\"Mon sujet, c’est la guerre, et ce qu'elle a de pitoyable.\" Wilfred Owen a écrit des textes poignants sur les ravages de la guerre… Le temps d'une randonnée, écoutez ses poèmes émouvants.  Gratuit. Inscription obligatoire sur le site du département en cliquant ici.\",\"Venez participer au loto familial organisé par le collectif \"Séjour Montagne 2023\" ! Le Dimanche 10 Septembre à 14h ( ouverture des portes à 13h30) à la salle des fêtes de Busigny ! - 4 séries loto (1€ le carton) - 1 bingo (2 € le carton) - 1 loto chinois Paiement des cartons à l'inscription A gagner : 2 cartes cadeaux d'une valeur de 100€ et pleins d'autres lots de valeur ! Petite restauration sur place ( nourriture / alimentation extérieure interdite) Inscriptions obligatoires avant le 05 Septembre aux numéros suivant : Centre social La Passerelle : 03.27.76.26.75 EVS de Ligny : 07.84.32.15.34 EVS \"Espace Sud\" Caudry : 06.99.98.58.63 EVS de Busigny : 06.71.19.30.82\",\"Le saviez-vous ? A Wallers-Arenberg, vous pouvez admirer un site minier remarquablement conservé et qui a su trouver une nouvelle vie : Arenberg Creative Mine, pôle image d’excellence ! Et si vous vous laissiez tenter par une visite en compagnie d’un ancien mineur ? L’occasion de rentrer dans certains bâtiments et de revivre la vie du mineur grâce aux différentes anecdotes qui vous seront racontées. Vous ne pourrez pas descendre au fond mais une visite en extérieur vous permettra de visualiser la grandeur du site ! À partir du 8 juin, visites guidées le jeudi à 15h. À partir de juillet, visites guidées certains mardis à 9h30 et le jeudi à 15h Le tarif est de 6 € pour les adultes et de 3 € pour les enfants. Réservations et renseignements auprès de M. Cottel, Association de défense et de protection du patrimoine historique et culturel de Wallers-Arenberg au +33 (0)6 04 15 05 44 © CAPH - Florence Delferière\",\"Pauline d'UP & Go, coach en développement personnel et bien-être vous accompagnera durant un atelier/coaching de 3h centré sur votre équilibre émotionnel, physique et environnemental. Grâce à son expérience personnelle et ses compétences d’Ingénieure Pédagogique, elle vous guidera tout en douceur à travers cet atelier collectif.\"Le but est de bâtir avec le potentiel du collectif.Partager ensemble nos réflexions, nos expériences et vous donner des clés qui pourraient changer vos vies et retrouver un équilibre au quotidien.\"\",\"La ville de Cambrai accueillera le relais de la flamme de Paris 2024 le 2 juillet 2024.\",...,\"Les Heures de Jean Carpentin Jeudi 5 octobre à 18h Durée : 1h30 Jauge : 30 Réservation en ligne au préalable sur www.tourismevalenciennes.fr Dans le cadre du cycle culturel Héritage, présentation à deux voix de la dernière acquisition patrimoniale de la médiathèque : le livre d’heures de la famille Carpentin, tout droit sorti de l’atelier du « prince des enlumineurs », Simon Marmion.\",\"Spectacle \"Spelling Spectacle\" avec Ingrid Berger Myhre Les 24 et 25 novembre 2023 à l'Espace Pasolini (dès 15 ans) Chez Ingrid Berger Myhre, la danse se mue en voyage vers l’inattendu. Après un premier spectacle poétique sur la relation entre le langage et la danse, la chorégraphe norvégienne invite à une croisière sur les rives de la logique. Avec le lien entre l’action et le langage comme fil conducteur, nous nous laissons conduire d’îlots de logique en scènes de la vie courante. En terres inconnues, les trois interprètes découvrent de nouvelles conséquences et possibilités à leurs gestes. Elles explorent, d’une scène à l’autre, un terrain de jeu à mi-chemin entre le réel et l’imaginaire, simplement guidées par des raisonnements logiques et des associations d’idées. Une programmation de l’Espace Pasolini\",\"Concert de jazz à l'Avant-Scène \"Clelya Abraham Quartet\" Clélya Abraham, Antonin Fresson, Laurent-Emmanuel « Tilo » Bertholo, Samuel F’hima Mercredi 21 février 2024 à 20h au phénix Figure emblématique de la nouvelle scène du jazz français, née dans une famille d’instrumentistes et de producteurs, Clelya Abraham n’a pas peur d’improviser : chacun de ses concerts raconte une histoire inédite. Brillante, la musicienne intègre de nombreux groupes dont Crafting Quintet. Dans son premier album solo, La Source, la jeune guadeloupéenne fait honneur à son héritage afro-caribéen.\",\"Concert à l'Avant-Scène du phénix \"Music for two\" avec Alice Julien-Laferrière et Mathilde Vialle Samedi 24 février 2024 à 19h au phénix Le Duo Coloquintes puise dans le répertoire virtuose des virginalistes anglais du XVIIe siècle, et propose des transcriptions inédites pour une viole et un violon de ce répertoire initialement écrit pour clavier. Jouées à la Cour élisabéthaine puis à la maison Stuart, les œuvres de ce concert se suivent en une alternance réfléchie de moments fiers, souvent très dansants ou doux, voire tout à fait caressants. Aux côtés des pièces extraites du Fitzwilliam Virginal Book on y entendra les Captaine Humes Lamentations du violiste Tobias Hume et des variations sur John come kisse me now de Thomas Baltzar, extraites des fameux recueils de Playford. Des transcriptions fascinantes aux multiples couleurs.\",\"Anne Versailles vous invite à redécouvrir le canal et ses rivages au travers d'une balade alliant apéro soft et ambiance sonore.Portez un regard neuf sur les paysages qui vous entourent, en vous promenant au fil de l'eau, ou confortablement installé sur un transat.\"]]\n",
       "labels: [[[0,1,0,0,0,...,0,0,0,0,0],[0,0,0,1,0,...,0,0,0,0,0],...,[0,0,0,0,0,...,0,0,0,0,0],[1,0,0,0,0,...,0,0,0,0,0]]]\n",
       "__index_level_0__: [[118,39,281,367,131,...,194,223,253,255,370]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "#val_df.head(2)\n",
    "test_ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximekuil/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SetFitModel.from_pretrained(\"dangvantuan/sentence-camembert-base\", multi_target_strategy=\"one-vs-rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "/Users/maximekuil/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "Map: 100%|██████████| 312/312 [00:00<00:00, 14749.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    batch_size=3,\n",
    "    num_epochs=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    column_mapping={\"description\": \"text\", \"labels\": \"label\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 74524\n",
      "  Batch size = 3\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 24842\n",
      "  0%|          | 0/24842 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.411, 'learning_rate': 8.048289738430585e-09, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/setfit/trainer.py:410\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, args, trial, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m train_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_to_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n\u001b[1;32m    406\u001b[0m full_parameters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    407\u001b[0m     train_parameters \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_to_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataset) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataset \u001b[38;5;28;01melse\u001b[39;00m train_parameters\n\u001b[1;32m    408\u001b[0m )\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfull_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_classifier(\u001b[38;5;241m*\u001b[39mtrain_parameters, args\u001b[38;5;241m=\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/setfit/trainer.py:462\u001b[0m, in \u001b[0;36mTrainer.train_embeddings\u001b[0;34m(self, x_train, y_train, x_eval, y_eval, args)\u001b[0m\n\u001b[1;32m    459\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Total optimization steps = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_train_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    461\u001b[0m warmup_steps \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(total_train_steps \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mwarmup_proportion)\n\u001b[0;32m--> 462\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_sentence_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/setfit/trainer.py:642\u001b[0m, in \u001b[0;36mTrainer._train_sentence_transformer\u001b[0;34m(self, model_body, train_dataloader, eval_dataloader, args, loss_func, warmup_steps)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_func(features, labels)\n\u001b[0;32m--> 642\u001b[0m     \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(loss_func\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n\u001b[1;32m    644\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Simplon/fine-tune-classification/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
